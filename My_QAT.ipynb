{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNkoog0SZ5/3JznP1hLwr/o",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/z4ziad/TensorFlow/blob/main/My_QAT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quantization Aware Training Notebook Example\n",
        "This notebook shows the effect if any of quantization-aware training on a simple ConvNet model trained on the MNIST dataset."
      ],
      "metadata": {
        "id": "d7Qxr5diHMej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install TensorFlow model optimization"
      ],
      "metadata": {
        "id": "f_nSfLvk-wDV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s4PNMdHz30-E"
      },
      "outputs": [],
      "source": [
        "! pip install -q tensorflow-model-optimization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "print(\"TF versoin: \", tf.__version__)\n",
        "\n",
        "from tensorflow import keras\n",
        "import tensorflow_model_optimization as tfmot\n",
        "print(\"TensorFlow Model Optimizaiton version:\", tfmot.__version__)"
      ],
      "metadata": {
        "id": "pkPYaM6c_MY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import MNIST dataset and normalize it"
      ],
      "metadata": {
        "id": "4aHD32yM_dCg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 to 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0"
      ],
      "metadata": {
        "id": "Yj8rp8tM_b8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build a model with quantization annotations to use for quantization aware training"
      ],
      "metadata": {
        "id": "f4YT5UytAcR3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
        "\n",
        "# Define the model architecture.\n",
        "model = keras.Sequential([\n",
        "  quantize_annotate_layer(keras.layers.InputLayer(input_shape=(28, 28))),\n",
        "  quantize_annotate_layer(keras.layers.Reshape(target_shape=(28, 28, 1))),\n",
        "  quantize_annotate_layer(keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu')),\n",
        "  #keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "  quantize_annotate_layer(keras.layers.MaxPooling2D(pool_size=(2, 2))),\n",
        "  quantize_annotate_layer(keras.layers.Flatten()),\n",
        "  quantize_annotate_layer(keras.layers.Dense(10))\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print(\"trainin baseline model...\")\n",
        "model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=1,\n",
        "  validation_split=0.1,\n",
        "  #validation_data=(test_images, test_labels)\n",
        ")"
      ],
      "metadata": {
        "id": "9_LfR4deA6vD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantization awareness has not been applied yet. To make the model quantization-aware, we need we get a new quantization aware model by calling `quantize_apply(model)`  "
      ],
      "metadata": {
        "id": "0Wom2P8HBOsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_aware_model = tfmot.quantization.keras.quantize_apply(model)\n",
        "# We need to recompile the model after applying quantization awarness\n",
        "quantized_aware_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "quantized_aware_model.summary()\n",
        "\n",
        "print(\"training quantized model...\")\n",
        "quantized_aware_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=1,\n",
        "  validation_split=0.1,\n",
        "  #validation_data=(test_images, test_labels)\n",
        ")"
      ],
      "metadata": {
        "id": "E1fw8DSTB49j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the accuracy on the test_mages"
      ],
      "metadata": {
        "id": "HMKlelQhCkgw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "_, baseline_model_accuracy = model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "_, q_aware_model_accuracy = quantized_aware_model.evaluate(\n",
        "   test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Quant test accuracy:', q_aware_model_accuracy)"
      ],
      "metadata": {
        "id": "wm_G8hQnCpjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let convert the quantized-aware model to TFLite model"
      ],
      "metadata": {
        "id": "ww33IvVfC094"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"converting quantized model to tflite...\")\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(quantized_aware_model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "quantized_tflite_model = converter.convert()\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on every image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for i, test_image in enumerate(test_images):\n",
        "    if i % 1000 == 0:\n",
        "      print('Evaluated on {n} results so far.'.format(n=i))\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "    test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, test_image)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "  accuracy = (prediction_digits == test_labels).mean()\n",
        "  return accuracy\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "metadata": {
        "id": "PrenlR18DJFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, let's evalute the accuracy of the TFLite model on the test_images dataset:"
      ],
      "metadata": {
        "id": "L0FCmLmODnpn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_tflite_accuracy = evaluate_model(interpreter)\n",
        "print('Quant TFLite test_accuracy:', test_tflite_accuracy)"
      ],
      "metadata": {
        "id": "PFy4c4KgDj_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now compare the TFLite test_accuracy with the base model and the quantization-aware-model:"
      ],
      "metadata": {
        "id": "HWUVnCPCF7_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Baseline test accuracy:', baseline_model_accuracy)\n",
        "print('Quant test accuracy:', q_aware_model_accuracy)\n",
        "print('Quant TFLite test_accuracy:', test_tflite_accuracy)"
      ],
      "metadata": {
        "id": "h7HzOLSlGFy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a sanity check, let's build the same model without annotation and check its accuracy"
      ],
      "metadata": {
        "id": "3hnjHrm-Gpfd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the model architecture.\n",
        "sanity_model = keras.Sequential([\n",
        "  keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "  keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "  keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu'),\n",
        "  #keras.layers.Conv2D(filters=16, kernel_size=(3, 3), activation=tf.nn.relu),\n",
        "  keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "  keras.layers.Flatten(),\n",
        "  keras.layers.Dense(10)\n",
        "])\n",
        "\n",
        "# Train the digit classification model\n",
        "sanity_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "sanity_model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=1,\n",
        "  #validation_split=0.1,\n",
        "  validation_data=(test_images, test_labels)\n",
        ")\n",
        "\n",
        "_, sanity_model_accuracy = sanity_model.evaluate(\n",
        "    test_images, test_labels, verbose=0)\n",
        "\n",
        "print('Sanity test accuracy:', sanity_model_accuracy)"
      ],
      "metadata": {
        "id": "eRJ-oO9VGhIC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}